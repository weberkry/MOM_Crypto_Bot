{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b546a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9bcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "883a2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# own functions\n",
    "from mom import influxDB_utils as influx\n",
    "from mom import Mandelbrot\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "#import faiss\n",
    "import hnswlib\n",
    "\n",
    "#news\n",
    "from newsapi import NewsApiClient\n",
    "import praw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "283d7717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "db580162657a4278b9d51810b7b67eed\n"
     ]
    }
   ],
   "source": [
    "# Load env from project root\n",
    "load_dotenv()\n",
    "\n",
    "#the following entries are expected in the MOM_Crypto_Bot/.env\n",
    "ASSET = os.getenv(\"ASSET\")\n",
    "CURRENCY = os.getenv(\"CURRENCY\")\n",
    "\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "#OPENAI_TEMPERATURE = float(os.getenv(\"OPENAI_TEMPERATURE\", \"0.0\"))\n",
    "\n",
    "NEWSAPI_KEY = os.getenv(\"NEWSAPI_KEY\")\n",
    "REDDIT_ID = os.getenv(\"REDDIT_CLIENT_ID\")\n",
    "REDDIT_SECRET = os.getenv(\"REDDIT_SECRET\")\n",
    "\n",
    "#print(OPENAI_KEY)\n",
    "#print(NEWSAPI_KEY)\n",
    "\n",
    "\n",
    "openai.api_key = OPENAI_KEY\n",
    "\n",
    "#client = OpenAI(api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "608927e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417bca53f524447fa115730ba03b70fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5b7d6ecceb477fba16b32990bdf5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02e93dca6eb466ea51d7b3803c1308d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bb396572db490a91c89de255c89e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f8b1f83eb34206ba6087392e00b594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8b3a5d52504e0c9013b4ebd56abe2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebf1866cb3144f0b6ae0869c96a48b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cffaf0d38d44a3bb148305ec7f58c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295fd0a44e87430fa50ebc865660694d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b1e56e67134d29adfcf0824292b90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691cef0551fe42b383453e3ab8983aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- embedding model + index (global) ----\n",
    "EMB_MODEL_NAME = \"all-MiniLM-L6-v2\"  # small & fast; change if you want larger\n",
    "embed_model = SentenceTransformer(EMB_MODEL_NAME)\n",
    "DIM = embed_model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b11f5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hnswlib index (in-memory). Persist/restore if needed.\n",
    "_index = hnswlib.Index(space=\"cosine\", dim=DIM)\n",
    "_index_initialized = False\n",
    "_articles_store = {}  # id -> metadata + text\n",
    "\n",
    "def init_index(max_elements=20000):\n",
    "    global _index_initialized\n",
    "    if not _index_initialized:\n",
    "        _index.init_index(max_elements=max_elements, ef_construction=200, M=16)\n",
    "        _index.set_ef(50)\n",
    "        _index_initialized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d4a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "484b7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1) Hurst helpers ----\n",
    "def get_latest_hurst(asset: str, lookback_days=30):\n",
    "    \"\"\"Query InfluxDB for latest hurst value for asset.\"\"\"\n",
    "    client = influx.get_client()\n",
    "    q = f'''\n",
    "    from(bucket: \"Hurst\")\n",
    "      |> range(start: -{lookback_days}d)\n",
    "      |> filter(fn: (r) => r._measurement == \"hurst\" and r.asset == \"{asset}\")\n",
    "      |> last()\n",
    "    '''\n",
    "    query_api = client.query_api()\n",
    "    tables = query_api.query(org=influx.INFLUX_ORG, query=q)\n",
    "    if not tables or not tables[0].records:\n",
    "        return None\n",
    "    rec = tables[0].records[0]\n",
    "    # value might be in rec.get_value() or rec.get_field()\n",
    "    try:\n",
    "        value = float(rec.get_value())\n",
    "    except Exception:\n",
    "        value = float(rec.get_field()) if rec.get_field() else None\n",
    "    return value\n",
    "\n",
    "def categorize_hurst(h: float):\n",
    "    if h is None:\n",
    "        return \"unknown\"\n",
    "    if h < 0.45:\n",
    "        return \"high_volatility\"\n",
    "    elif h < 0.55:\n",
    "        return \"random_walk\"\n",
    "    else:\n",
    "        return \"trending\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeeadf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = get_latest_hurst(ASSET)\n",
    "h = categorize_hurst(H)\n",
    "\n",
    "print(H,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 2) News fetch + preprocessing ----\n",
    "newsapi = NewsApiClient(api_key=NEWSAPI_KEY)\n",
    "\n",
    "def fetch_newsapi_articles(query: str, from_dt: datetime = None, page_size=50) -> List[Dict]:\n",
    "    \"\"\"Return list of article dicts: {title, description, content, url, publishedAt, source}\"\"\"\n",
    "    params = {\"q\": query, \"pageSize\": page_size, \"language\": \"en\", \"sortBy\": \"publishedAt\"}\n",
    "    if from_dt:\n",
    "        params[\"from_param\"] = from_dt.isoformat()\n",
    "    res = newsapi.get_everything(**params)\n",
    "    articles = res.get(\"articles\", [])\n",
    "    cleaned = []\n",
    "    for a in articles:\n",
    "        cleaned.append({\n",
    "            \"title\": a.get(\"title\") or \"\",\n",
    "            \"description\": a.get(\"description\") or \"\",\n",
    "            \"content\": (a.get(\"content\") or \"\")[:4000],  # cap\n",
    "            \"url\": a.get(\"url\"),\n",
    "            \"publishedAt\": a.get(\"publishedAt\"),\n",
    "            \"source\": a.get(\"source\", {}).get(\"name\")\n",
    "        })\n",
    "    return cleaned\n",
    "\n",
    "def chunk_text(txt: str, max_words=200):\n",
    "    \"\"\"Simple chunker by words.\"\"\"\n",
    "    words = txt.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_words):\n",
    "        chunks.append(\" \".join(words[i:i+max_words]))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 3) Indexing ----\n",
    "def add_articles_to_index(articles: List[Dict], prefix_id=0):\n",
    "    \"\"\"Index article chunks. Returns dict of id->meta.\"\"\"\n",
    "    init_index(max_elements=max(10000, len(articles)*4))\n",
    "    current_max_id = max(_articles_store.keys())+1 if _articles_store else 0\n",
    "    idx = current_max_id\n",
    "    texts = []\n",
    "    metas = []\n",
    "    for art in articles:\n",
    "        full_text = \" \".join([art[\"title\"], art[\"description\"], art[\"content\"]])\n",
    "        chunks = chunk_text(full_text, max_words=200)\n",
    "        for chunk in chunks:\n",
    "            texts.append(chunk)\n",
    "            metas.append({\n",
    "                \"title\": art[\"title\"],\n",
    "                \"url\": art[\"url\"],\n",
    "                \"source\": art[\"source\"],\n",
    "                \"publishedAt\": art[\"publishedAt\"]\n",
    "            })\n",
    "    if not texts:\n",
    "        return {}\n",
    "    embeddings = embed_model.encode(texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "    ids = list(range(idx, idx + len(texts)))\n",
    "    _index.add_items(embeddings, ids)\n",
    "    for i, m in zip(ids, metas):\n",
    "        _articles_store[i] = {\"text\": texts[i-idx], \"meta\": m}\n",
    "    return {i: _articles_store[i] for i in ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 4) Retrieval ----\n",
    "def retrieve(query: str, k=5):\n",
    "    vec = embed_model.encode([query], convert_to_numpy=True)\n",
    "    labels, distances = _index.knn_query(vec, k=k)\n",
    "    results = []\n",
    "    for lid in labels[0]:\n",
    "        if lid in _articles_store:\n",
    "            results.append({**_articles_store[lid][\"meta\"], \"text\": _articles_store[lid][\"text\"], \"id\": lid})\n",
    "    return results\n",
    "\n",
    "# ---- 5) LLM prompt + call ----\n",
    "def build_prompt(asset: str, hurst_value: float, hurst_cat: str, retrieved: List[Dict]):\n",
    "    header = f\"Asset: {asset}\\nHurst: {hurst_value}\\nHurst_category: {hurst_cat}\\n\\n\"\n",
    "    header += \"You are a financial risk analyst. Using the Hurst signal (above) and the news snippets below, produce a concise risk evaluation (1-3 short paragraphs) with:\\n\"\n",
    "    header += \"- a single-line risk level (LOW / MEDIUM / HIGH)\\n- a short justification referencing the Hurst signal and at least two article snippets by source+date.\\n- suggestions for monitoring (what to watch next).\\n\\n\"\n",
    "    prompt = header + \"News snippets (most relevant first):\\n\"\n",
    "    for r in retrieved:\n",
    "        pub = r.get(\"publishedAt\")\n",
    "        src = r.get(\"source\")\n",
    "        title = r.get(\"title\", \"\") if \"title\" in r else \"\"\n",
    "        snippet = r.get(\"text\")[:800]\n",
    "        prompt += f\"\\n[{src} | {pub}] {title}\\n{snippet}\\n---\\n\"\n",
    "    prompt += \"\\nNow give the risk evaluation. Be concise and include explicit references to the Hurst signal and news snippets.\\n\"\n",
    "    return prompt\n",
    "\n",
    "def ask_llm(prompt: str, model: str = OPENAI_MODEL, temperature=OPENAI_TEMPERATURE, max_tokens=600):\n",
    "    \"\"\"Calls OpenAI ChatCompletion in a minimal single-turn fashion.\"\"\"\n",
    "    # Use Chat Completions API\n",
    "    messages = [{\"role\":\"system\", \"content\": \"You are a professional quantitative risk analyst.\"},\n",
    "                {\"role\":\"user\", \"content\": prompt}]\n",
    "    resp = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "# ---- 6) Orchestration ----\n",
    "def run_rag_risk(asset=\"BTC\", lookback_news_days=7, top_k=5):\n",
    "    # 1) hurst\n",
    "    h = get_latest_hurst(asset)\n",
    "    hcat = categorize_hurst(h)\n",
    "    # 2) fetch news\n",
    "    since = datetime.now(timezone.utc) - timedelta(days=lookback_news_days)\n",
    "    articles = fetch_newsapi_articles(asset, from_dt=since, page_size=50)\n",
    "    if not articles:\n",
    "        return {\"error\":\"no articles\"}\n",
    "    # 3) index articles\n",
    "    add_articles_to_index(articles)\n",
    "    # 4) retrieve relevant items\n",
    "    retrieved = retrieve(asset, k=top_k)\n",
    "    # 5) build prompt and ask llm\n",
    "    prompt = build_prompt(asset, h, hcat, retrieved)\n",
    "    llm_result = ask_llm(prompt)\n",
    "    out = {\n",
    "        \"asset\": asset,\n",
    "        \"hurst_value\": h,\n",
    "        \"hurst_cat\": hcat,\n",
    "        \"retrieved\": retrieved,\n",
    "        \"llm_result\": llm_result,\n",
    "        \"timestamp\": datetime.now(timezone.utc).isoformat()\n",
    "    }\n",
    "    return out\n",
    "\n",
    "# example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running RAG evaluator for BTC...\")\n",
    "    result = run_rag_risk(\"BTC\")\n",
    "    print(result[\"llm_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f56f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97c1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee6e3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f35692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding helper\n",
    "def embed_texts(texts, model=\"text-embedding-3-small\"):\n",
    "    resp = client.embeddings.create(model=model, input=texts)\n",
    "    return [np.array(e.embedding, dtype=np.float32) for e in resp.data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042d00ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 9, 16, 20, 57, 48, 509094)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f79e01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get news from newsapi\n",
    "asset = ASSET\n",
    "\n",
    "news = NewsApiClient(api_key=NEWSAPI_KEY)\n",
    "#print(news)\n",
    "\n",
    "from_date = \"2025-09-01\"  #use here timedelta to implement different intervals\n",
    "\n",
    "articles = news.get_everything(\n",
    "    q=ASSET,\n",
    "    from_param=from_date,\n",
    "    to=datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "    language=\"en\",\n",
    "    sort_by=\"relevancy\",\n",
    "    page_size=25\n",
    ").get(\"articles\", [])\n",
    "\n",
    "\n",
    "articel_content = [a.get(\"title\", \"\") + \". \" + (a.get(\"description\") or a.get(\"content\") or \"\")\n",
    "            for a in articles]\n",
    "\n",
    "#clean up\n",
    "cleaned = []\n",
    "for a in articles:\n",
    "    text = \" \".join(filter(None, [a.get(\"title\"), a.get(\"description\"), a.get(\"content\")]))\n",
    "    cleaned.append({\n",
    "            \"asset\": asset,\n",
    "            \"date\": a.get(\"publishedAt\"),\n",
    "            \"text\": text,\n",
    "            \"source\": a.get(\"source\", {}).get(\"name\")\n",
    "        })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d7a0b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$3.38 Billion in Bitcoin Options Expiry Raises Concerns of September Volatility. With $3.38 billion of Bitcoin BTC $110 973 24h volatility: 0.5% Market cap: $2.21 T Vol. 24h: $58.02 B options expiry on Sept. 5, BTC price is showing some...',\n",
       " 'BlackRock Continues to Offload Millions in Bitcoin, Ethereum, But for How Long?. BlackRock is the world’s largest asset manager and the leading institution in Bitcoin BTC $114 077 24h volatility: 1.5% Market cap: $2.27 T Vol. 24h: $52.57 ...',\n",
       " \"Businesses Buy 1,755 Bitcoin Daily, Adding $1.3 Trillion in 20 Months – BTC Above $125K Next?. If you click 'Accept all', we and our partners, including 237 who are part of the IAB Transparency &amp; Consent Framework, will also store and/or access information on a device (in other words, use … [+714 chars]\",\n",
       " 'How did Tether profit $13B in 2024 from USDT?. How Tether turned $113B in Treasuries into $13B profit - USDT is most profitable model in crypto history',\n",
       " 'Michael Saylor Breaks Silence on Big S&P 500 Index Rejection. Michael Saylor, the Chairman of business intelligence and software firm Strategy Inc (NASDAQ: MSTR), recently made a post on the negative response his...',\n",
       " 'Coinbase Hacker Is Betting on Ethereum – ETH Breakout?. Ethereum (ETH) has a strong advocate in the hacker who attacked customers of American cryptocurrency exchange Coinbase a while ago. According to on-chain...',\n",
       " 'Gold Outshines in 2025 as Bitcoin-Gold Ratio Eyes Q4 Breakout. Gold is the standout performer of 2025, climbing more than 33%. \\nThat’s three times the gain of the Nasdaq 100 index and nearly double bitcoin’s (BTC) performance. In practice that means it now takes just 31.2 ounces of gold to buy one BTC, a measure known as…',\n",
       " 'BTC/USD and DOGE/BTC Race Towards Bullish Breakout; XRP MACD Turns Bullish. Major cryptocurrencies are flashing bullish price patterns.',\n",
       " 'Billionaire Michael Saylor Purchases 525 BTC for $60.2M, Lifting Holdings to 638,985 BTC. Billionaire Michael Saylor’s Bitcoin strategy shows no signs of slowing down. Strategy has further cemented its reputation as the world’s largest corporate...',\n",
       " 'Bitcoin Maxis Sold 97K BTC Last Friday but Buyers Are Here for Rescue. Bitcoin’s BTC $109 877 24h volatility: 1.2% Market cap: $2.19 T Vol. 24h: $40.04 B long-term holders (LTHs) accelerated their selling last week when BTC...',\n",
       " 'Why Is Metaplanet Stock Down 5% as Its Holdings Cross 20K BTC?. Metaplanet stock has come under strong selling pressure on Sept. 1, despite the firm also announcing a 1,009 BTC BTC $110 242 24h volatility: 1.5% Market cap...',\n",
       " \"Peter Schiff Takes A Victory Lap As Gold Hit New All-Time High At $3,600: Bitcoin Is The 'Wrong Horse'. Bitcoin's (CRYPO: BTC) ongoing consolidation phase has sparked a heated debate, with critics pointing to gold's breakout as proof that BTC has lost steam.\\nWhat Happened: Bitcoin critic Peter Schiff noted that Gold (NYSE:GLD) surged to fresh all-time highs aro…\",\n",
       " \"MARA’s bitcoin stack nears $6 billion following production update, cementing spot as second-largest public holder after Strategy. MARA's bitcoin stack has reached 52,477 BTC — the second-largest public bitcoin treasury after Michael Saylor's Strategy.\",\n",
       " '6 wild gadgets you can plug into your headphone jack that aren’t about audio. You’ll never look at your old aux port the same way again.',\n",
       " 'A quick look at sextortion at scale: 1,900 messages and 205 Bitcoin addresses spanning four years, (Tue, Sep 2nd). What can almost 2,000 sextortion messages tell us about how threat actors operate and whether they are successful? Let&#x27s find out.',\n",
       " 'Strategy Adds 525 Bitcoin in Latest Purchase. The company boosted its holdings to 638,985 BTC after a new acquisition worth about $60.2 million.',\n",
       " \"Asia Morning Briefing: BTC Treasury Demand is Weakening, CryptoQuant Cautions. Despite record bitcoin treasury holdings, the sharp drop in average purchase size shows weakening institutional appetite, even as Taiwan's Sora Ventures prepares a $1 billion BTC Treasury fund.\",\n",
       " 'BTC Eyes $120K With Bullish H&S Pattern: Technical Analysis. Bitcoin is forming a bullish inverse head-and-shoulders pattern, according to technical charts.',\n",
       " \"Public Firm Bitcoin Holdings Top 1 Million BTC. With more than 630,000 coins, Michael Saylor's Strategy leads the pack as that milestone is hit.\",\n",
       " \"Michael Saylor's Strategy Buys Another 1,955 BTC for $217M. MicroStrategy expanded its bitcoin holdings with a $217 million purchase, amid recent investor pushback as the stock slides and its valuation relative to bitcoin weakens.\",\n",
       " 'Metaplanet Bitcoin Purchase Takes Holdings to 20K BTC, Overtaking Riot Platforms. 1,009 BTC purchase worth $112M is biggest since July, shares drop 5.5%',\n",
       " 'Satoshi-era wallet holding $50M in Bitcoin awakens after 11 years. After 12.8 years, Bitcoin whale wallet awakens with 479.44 BTC worth $53 million.',\n",
       " 'Bitcoin Ethereum, XRP, Dogecoin Maintain Uptrend Ahead Of Consumer Price Inflation Data. Cryptocurrency markets continued their upward momentum on Thursday morning.\\nCryptocurrency\\nTicker\\nPrice\\nBitcoin\\n(CRYPTO: BTC)\\n$114,056.31\\nEthereum\\n(CRYPTO: ETH)\\n$4,428.15\\nSolana\\n(CRYPTO: SOL)\\n$225.68\\nXRP\\n(CRYPTO: XRP)\\n$3.01\\nDogecoin\\n(CRYPTO: DOGE)\\n$0.2508\\nShi…',\n",
       " \"Bitcoin Rises As Traders Bet On Fed Rate Cut; Ethereum, XRP, Dogecoin Also Rally: Analyst Says Won't Be 'Surprised' If ETH Tops $10,000. Leading cryptocurrencies rallied alongside stocks on Thursday as investors raised risk appetite in anticipation of interest rate cuts.\\nCryptocurrency\\nGains +/-\\nPrice (Recorded at 9:40 p.m. ET)\\nBitcoin (CRYPTO: BTC)\\n+1.46%\\n$115,626.25\\nEthereum (CRYPTO: ETH) \\n+…\",\n",
       " 'Strive Taps Crypto Veterans To Guide $1.5 Billion Bitcoin Treasury Expansion. Strive Inc. (NASDAQ:ASST) shares tumbled sharply Monday as investors digested the company’s aggressive Bitcoin (CRYPTO: BTC/USD) accumulation plan. The...']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articel_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c8650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Embedding helper\n",
    "def embed_texts(texts, model=\"text-embedding-3-small\"):\n",
    "    resp = client.embeddings.create(model=model, input=texts)\n",
    "    return [np.array(e.embedding, dtype=np.float32) for e in resp.data]\n",
    "\n",
    "# Build hnswlib index\n",
    "def build_hnsw(texts, dim=1536):\n",
    "    embs = embed_texts(texts)\n",
    "    idx = hnswlib.Index(space=\"l2\", dim=dim)\n",
    "    idx.init_index(max_elements=len(embs), ef_construction=200, M=16)\n",
    "    idx.add_items(embs, list(range(len(embs))))\n",
    "    idx.set_ef(50)\n",
    "    return idx, embs\n",
    "\n",
    "# Query index\n",
    "def query_index(idx, texts, query, k=3):\n",
    "    q_emb = embed_texts([query])[0]\n",
    "    labels, _ = idx.knn_query(q_emb, k=k)\n",
    "    return [texts[i] for i in labels[0]]\n",
    "\n",
    "# Fetch functions\n",
    "def fetch_news(keyword, days=7, limit=50):\n",
    "    news = NewsApiClient(api_key=NEWSAPI_KEY)\n",
    "    from_date = (datetime.utcnow() - timedelta(days=days)).isoformat()\n",
    "    articles = news.get_everything(q=keyword, from_param=from_date,\n",
    "                                   to=datetime.utcnow().isoformat(),\n",
    "                                   language='en', sort_by='relevancy',\n",
    "                                   page_size=limit).get(\"articles\", [])\n",
    "    return [a.get(\"title\", \"\") + \". \" + (a.get(\"description\") or a.get(\"content\") or \"\")\n",
    "            for a in articles]\n",
    "\n",
    "def fetch_reddit(keyword, subreddits=[\"CryptoCurrency\"], limit=50):\n",
    "    reddit = praw.Reddit(client_id=REDDIT_ID, client_secret=REDDIT_SECRET,\n",
    "                         user_agent=\"crypto-risk-app/0.1\")\n",
    "    posts = []\n",
    "    for sub in subreddits:\n",
    "        for post in reddit.subreddit(sub).search(keyword, sort=\"new\", limit=limit):\n",
    "            posts.append(post.title + \". \" + (post.selftext or \"\"))\n",
    "    return posts\n",
    "\n",
    "# Risk evaluation\n",
    "def evaluate_risk(asset, hurst_val, context_texts):\n",
    "    prompt = f\"\"\"\n",
    "Asset: {asset}\n",
    "Hurst exponent: {hurst_val:.3f}\n",
    "\n",
    "Media context:\n",
    "{\"\\n\".join(context_texts)}\n",
    "\n",
    "Give a JSON with keys:\n",
    " - asset\n",
    " - hurst_value\n",
    " - risk_level (low|medium|high)\n",
    " - explanation\n",
    "    \"\"\"\n",
    "    resp = client.chat.completions.create(model=\"gpt-4o-mini\",\n",
    "                                          messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "                                          response_format={\"type\":\"json_object\"})\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "# Main pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    asset = \"BTC\"\n",
    "    # Assume hurst_value computed elsewhere\n",
    "    hurst_value = 0.57\n",
    "\n",
    "    news_texts = fetch_news(asset, days=7)\n",
    "    reddit_texts = fetch_reddit(asset, [\"CryptoCurrency\", \"Bitcoin\"], limit=30)\n",
    "    all_texts = news_texts + reddit_texts\n",
    "\n",
    "    index, _ = build_hnsw(all_texts, dim=len(embed_texts([\"\"])[0]))  # auto-dim\n",
    "    context = query_index(index, all_texts, f\"{asset} risk\", k=5)\n",
    "\n",
    "    risk_json = evaluate_risk(asset, hurst_value, context)\n",
    "    print(risk_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eaa668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init LLM + embeddings\n",
    "client = OpenAI()\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get analysis from InfluxDB\n",
    "def fetch_hurst(asset: str, interval: str, start: str = \"2020-01-01\") -> float:\n",
    "    \"\"\"Query InfluxDB and compute Hurst exponent for asset.\"\"\"\n",
    "    df = query_dataframe(asset=asset, interval=interval, start=start)\n",
    "    if df.empty:\n",
    "        return None\n",
    "    h = hurst()\n",
    "    return h.fit(df[\"return\"].dropna().values, power=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_media(asset: str, days: int = 7):\n",
    "    \"\"\"Placeholder: fetch news + Reddit posts for the asset.\"\"\"\n",
    "    # TODO: replace with real APIs (Reddit, NewsAPI, etc.)\n",
    "    return [\n",
    "        f\"{asset} adoption rises after exchange listing\",\n",
    "        f\"Reddit buzz about {asset} volatility and risks\",\n",
    "        f\"Analysts discuss regulation impact on {asset}\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6dd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_vectorstore(docs):\n",
    "    \"\"\"Embed and store documents in FAISS index.\"\"\"\n",
    "    global documents\n",
    "    embeddings = embedder.encode(docs, convert_to_numpy=True)\n",
    "    index.add(embeddings)\n",
    "    documents.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa9150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index_hnsw(embeddings):\n",
    "    dim = embeddings.shape[1]\n",
    "    p = hnswlib.Index(space='l2', dim=dim)\n",
    "    p.init_index(max_elements=embeddings.shape[0], ef_construction=200, M=16)\n",
    "    p.add_items(embeddings, ids=np.arange(embeddings.shape[0]))\n",
    "    p.set_ef(50)\n",
    "    return p\n",
    "\n",
    "def retrieve_hnsw(index, docs, query_emb, k=5):\n",
    "    labels, distances = index.knn_query(query_emb, k=k)\n",
    "    return [docs[i] for i in labels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_eval(asset: str, hurst_val: float, context_docs: list):\n",
    "    \"\"\"LLM combines hurst + context into risk evaluation.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a financial risk analyst.\n",
    "    Asset: {asset}\n",
    "    Hurst exponent: {hurst_val:.3f} ( >0.5 trending, <0.5 mean-reverting )\n",
    "\n",
    "    Recent media context:\n",
    "    {chr(10).join(context_docs)}\n",
    "\n",
    "    Based on this, give a structured JSON risk evaluation with:\n",
    "    - risk_level: (low, medium, high)\n",
    "    - rationale: short text\n",
    "    \"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return resp.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7142a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedder.encode(doc_texts, convert_to_numpy=True)\n",
    "index = build_index_hnsw(embeddings)\n",
    "\n",
    "q_emb = embedder.encode([query], convert_to_numpy=True)\n",
    "top_docs = retrieve_hnsw(index, doc_texts, q_emb, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === pipeline run ===\n",
    "if __name__ == \"__main__\":\n",
    "    asset = \"BTC\"\n",
    "\n",
    "    # 1. Market data\n",
    "    hurst_val = fetch_hurst(asset, \"Day\")\n",
    "\n",
    "    # 2. Media\n",
    "    docs = fetch_media(asset)\n",
    "    add_to_vectorstore(docs)\n",
    "\n",
    "    # 3. RAG\n",
    "    context = retrieve_context(f\"{asset} risk factors\", k=3)\n",
    "\n",
    "    # 4. LLM evaluation\n",
    "    result = risk_eval(asset, hurst_val, context)\n",
    "\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MOM)",
   "language": "python",
   "name": "mom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
